# Title: Investment_webscrapping

## Table of Contents

1. [Description](#description)
2. [Pre-requisite](#pre-requisite)
3. [Installation guide](#installation-guide)
4. [User Guide](#user-guide)
5. [Roadmap](#roadmap)
6. [LICENSE](#license)
7. [Contributors](#contributors)
9. [FAQS](#faqs)
10. [MISCELLANOUS](#miscellanous)

## Description:

**This project has 2 goals:**

<!--[!CAUTION]-->
    1) *Helping me in my investing strategies by gathering the financials datas of interesting companies*

<!--[!IMPORTANT]-->
    2) *Starting a data scientist portfolio*

<!--[!WARNING]
    3) _Improving my programming knowledge using in this case, web scrapping through python_

[!TIP]
    4) ~~Earning money...~~


[!NOTE]
<ins>The first commit will show a usable code and the following commits will improve the coding structure.</ins> :+1:


simple footnote[¹]

another one [²]

[¹]:footnote [url](https://github.com/S-S-Zheng/Investment_webscrapping)

[²]:footnote2 [url2](https://www.youtube.com/)

-->

##### Final structure of the project:

![Project structure : Final structure of the project](pic1.png)

<img alt="Project structure : Final structure of the project" src="img/pic1.png" />


## Pre-requisite:

- Python >= 3.9 (`python3 -V`)
- Git >= 2.34 (`git --version`)
- pip >= 24.0 (`pip --version`)
The versions and dependencies required are showned in the setup.py and requirements.txt.
[!NOTE]
setup.py is used to define a reusable package and will likely contains the minimal functional dependencies (>=) capable to run the code (through pip install . or python setup.py install). The main point here is to create a reusable, documentated and sharable package whereas requirements.txt indicates the exactes dependencies required (pip install -r requirements.txt and can be froze with pip freeze > requirements.txt). You can't put metadatas (author, version, dependencies etc...) or on PyPI.

## Installation guide:

~~~
mkdir project_name
cd project_name
git clone https://github.com/S-S-Zheng/Investment_webscrapping.git
python3 venv path/to/venv
source venv/bin/activate
pip install .
python3 main.py
~~~

## User guide:


## Roadmap:

##### TODO - Make it works : DONE

##### TODO - Reshape its structure : DONE

##### TODO - Fix the tests forlder : DONE

##### TODO - Add the files/folders to ignore in the .gitingore: DONE

##### TODO - Correct values in millions and shares in thousand: DONE

##### TODO - Correct subplots and sub legends : ALTERNATIVE Make_graphs_nosubplot.py

##### TODO - Correct the Make_graphs_nosubplots.py : DONE but the sublegends positions aren't dynamics ==> Need improvements

##### TODO - Add and correct the calendar of events: DONE

##### TODO - Correct the summary before exporting due to hazardous calendar: DONE

##### TODO - Remove useless lines: Working progress

##### TODO - Add ratios?ROIC?: DONE

##### TODO - Re-work the modules to make them "base class": Working progress

##### TODO - Build a dynamic scrapping through Selenium or playwrights: FAILED due to CRSF TOKEN issues though I've learned alot.

## LICENSE:

[MIT](https://choosealicense.com/licenses/mit/)

## Contributors:


## FAQS:

<!--
***
A list of frequently asked questions
1. **This is a question in bold**
Answer of the first question with _italic words_.
2. __Second question in bold__
To answer this question we use an unordered list:
* First point
* Second Point
* Third point
3. **Third question in bold**
Answer of the third question with *italic words*.
4. **Fourth question in bold**
| Headline 1 in the tablehead | Headline 2 in the tablehead | Headline 3 in the tablehead |
|:--------------|:-------------:|--------------:|
| text-align left | text-align center | text-align right |

-->

## MISCELLANOUS:

<!--
Images : [Image text](/path/to/the/screenshot.png)
links : [links](https://github.com/S-S-Zheng/Investment_webscrapping)
feedbacks...
-->